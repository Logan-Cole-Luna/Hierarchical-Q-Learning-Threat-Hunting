{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:32.160691Z",
     "iopub.status.busy": "2023-11-28T14:02:32.159081Z",
     "iopub.status.idle": "2023-11-28T14:02:32.29158Z",
     "shell.execute_reply": "2023-11-28T14:02:32.290112Z",
     "shell.execute_reply.started": "2023-11-28T14:02:32.160631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import  confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:33.892684Z",
     "iopub.status.busy": "2023-11-28T14:02:33.892087Z",
     "iopub.status.idle": "2023-11-28T14:02:33.906012Z",
     "shell.execute_reply": "2023-11-28T14:02:33.904944Z",
     "shell.execute_reply.started": "2023-11-28T14:02:33.892638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:37.423752Z",
     "iopub.status.busy": "2023-11-28T14:02:37.422774Z",
     "iopub.status.idle": "2023-11-28T14:02:47.379183Z",
     "shell.execute_reply": "2023-11-28T14:02:47.377587Z",
     "shell.execute_reply.started": "2023-11-28T14:02:37.423694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"models/DDQN_model.json\", \"r\") as jfile:\n",
    "    model = model_from_json(json.load(jfile))\n",
    "model.load_weights(\"models/DDQN_model.h5\")\n",
    "\n",
    "\n",
    "model.compile(loss=huber_loss, optimizer=\"sgd\")\n",
    "\n",
    "env = NetworkClassificationEnv('test', label_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:47.383534Z",
     "iopub.status.busy": "2023-11-28T14:02:47.382624Z",
     "iopub.status.idle": "2023-11-28T14:04:19.474724Z",
     "shell.execute_reply": "2023-11-28T14:04:19.473562Z",
     "shell.execute_reply.started": "2023-11-28T14:02:47.383478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    " total_reward = 0\n",
    "    \n",
    "true_labels = np.zeros(len(env.attack_types),dtype=int)\n",
    "estimated_labels = np.zeros(len(env.attack_types),dtype=int)\n",
    "estimated_correct_labels = np.zeros(len(env.attack_types),dtype=int)\n",
    "\n",
    "states, labels = env.get_full()\n",
    "q = model.predict(states)\n",
    "actions = np.argmax(q, axis=1)        \n",
    "\n",
    "\n",
    "labs, true_labels = np.unique(labels, return_counts=True)\n",
    "\n",
    "for indx,a in enumerate(actions):\n",
    "    estimated_labels[a] +=1              \n",
    "    if a == labels[indx]:\n",
    "        total_reward += 1\n",
    "        estimated_correct_labels[a] += 1\n",
    "\n",
    "\n",
    "Accuracy = estimated_correct_labels / true_labels\n",
    "Mismatch = estimated_labels - true_labels\n",
    "\n",
    "print('\\r\\nTotal reward: {} | Number of samples: {} | Accuracy = {}%'.format(total_reward,\n",
    "      len(states),float(100*total_reward/len(states))))\n",
    "outputs_df = pd.DataFrame(index = env.attack_types,columns = [\"Estimated\",\"Correct\",\"Total\",\"Acuracy\"])\n",
    "for indx,att in enumerate(env.attack_types):\n",
    "    outputs_df.iloc[indx].Estimated = estimated_labels[indx]\n",
    "    outputs_df.iloc[indx].Correct = estimated_correct_labels[indx]\n",
    "    outputs_df.iloc[indx].Total = true_labels[indx]\n",
    "    outputs_df.iloc[indx].Acuracy = Accuracy[indx]*100\n",
    "    outputs_df.iloc[indx].Mismatch = abs(Mismatch[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:04:19.477484Z",
     "iopub.status.busy": "2023-11-28T14:04:19.476285Z",
     "iopub.status.idle": "2023-11-28T14:04:19.499547Z",
     "shell.execute_reply": "2023-11-28T14:04:19.497863Z",
     "shell.execute_reply.started": "2023-11-28T14:04:19.477418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "outputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:04:50.950266Z",
     "iopub.status.busy": "2023-11-28T14:04:50.949486Z",
     "iopub.status.idle": "2023-11-28T14:04:51.413369Z",
     "shell.execute_reply": "2023-11-28T14:04:51.412151Z",
     "shell.execute_reply.started": "2023-11-28T14:04:50.950205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "width = 0.35\n",
    "pos = np.arange(len(true_labels))\n",
    "p1 = plt.bar(pos, estimated_correct_labels,width,color='g')\n",
    "p1 = plt.bar(pos+width,\n",
    "             (np.abs(estimated_correct_labels-true_labels)),width,\n",
    "             color='r')\n",
    "p2 = plt.bar(pos+width,np.abs(estimated_labels-estimated_correct_labels),width,\n",
    "             bottom=(np.abs(estimated_correct_labels-true_labels)),\n",
    "             color='b')\n",
    "\n",
    "\n",
    "ax.set_xticks(pos+width/2)\n",
    "ax.set_xticklabels(env.attack_types,rotation='vertical')\n",
    "\n",
    "ax.set_title('Test set scores, Acc = {:.2f}'.format(100*total_reward/len(states)))\n",
    "plt.legend(('Correct estimated','False negative','False positive'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('results/ADFA_DDQN.svg', format='svg', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:04:51.891211Z",
     "iopub.status.busy": "2023-11-28T14:04:51.890383Z",
     "iopub.status.idle": "2023-11-28T14:04:57.35102Z",
     "shell.execute_reply": "2023-11-28T14:04:57.349664Z",
     "shell.execute_reply.started": "2023-11-28T14:04:51.89117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aggregated_data_test =labels\n",
    "\n",
    "print('Performance measures on Test data')\n",
    "print('Accuracy =  {:.4f}'.format(accuracy_score( aggregated_data_test,actions)))\n",
    "print('F1 =  {:.4f}'.format(f1_score(aggregated_data_test,actions, average='weighted')))\n",
    "print('Precision_score =  {:.4f}'.format(precision_score(aggregated_data_test,actions, average='weighted')))\n",
    "print('recall_score =  {:.4f}'.format(recall_score(aggregated_data_test,actions, average='weighted')))\n",
    "\n",
    "cnf_matrix = confusion_matrix(aggregated_data_test,actions)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=env.attack_types, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.savefig('results/confusion_matrix_DDQN_model.svg', format='svg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"processed_data/train_df.csv\")\n",
    "test_df = pd.read_csv(\"processed_data/test_df.csv\")\n",
    "\n",
    "with open('processed_data/class_weights.json', 'r') as f:\n",
    "    class_weights = json.load(f)\n",
    "with open('processed_data/label_dict.json', 'r') as f:\n",
    "    label_dict = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 902298,
     "sourceId": 1530359,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
