{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:32.160691Z",
     "iopub.status.busy": "2023-11-28T14:02:32.159081Z",
     "iopub.status.idle": "2023-11-28T14:02:32.29158Z",
     "shell.execute_reply": "2023-11-28T14:02:32.290112Z",
     "shell.execute_reply.started": "2023-11-28T14:02:32.160631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_cls:\n",
    "    def __init__(self, train_test, attack_map, **kwargs):\n",
    "        self.train_test = train_test\n",
    "        \n",
    "        if self.train_test == 'train':\n",
    "            self.train_path = \"train_df.csv\"\n",
    "        else:\n",
    "            self.test_path = \"test_df.csv\"\n",
    "\n",
    "        self.attack_map =   attack_map \n",
    "        self.attack_types = list(attack_map.keys())\n",
    "        \n",
    "        self.loaded = False\n",
    "    \n",
    "    def get_batch(self, batch_size=100):\n",
    "        if not self.loaded:\n",
    "            self._load_df()\n",
    "        \n",
    "        # Ensure batch_size does not exceed the DataFrame size\n",
    "        if batch_size > self.data_shape[0]:\n",
    "            raise ValueError(f\"batch_size ({batch_size}) cannot be larger than the dataset size ({self.data_shape[0]}).\")\n",
    "        \n",
    "        # Calculate wrapped indices using modulo\n",
    "        indexes = [(self.index + i) % self.data_shape[0] for i in range(batch_size)]\n",
    "        \n",
    "        # Update the index for the next batch\n",
    "        self.index = (self.index + batch_size) % self.data_shape[0]\n",
    "        \n",
    "        # Select the batch using iloc with valid indices\n",
    "        batch = self.df.iloc[indexes]\n",
    "        \n",
    "        map_type = pd.Series(index=self.attack_types, data=np.arange(len(self.attack_types))).to_dict()\n",
    "        labels = batch[label_col].map(self.attack_map).map(map_type).values\n",
    "        del batch[label_col]\n",
    "        \n",
    "        return np.array(batch), labels\n",
    "    \n",
    "    def get_full(self):\n",
    "\n",
    "        self._load_df()\n",
    "        \n",
    "        batch = self.df\n",
    "        map_type = pd.Series(index=self.attack_types,data=np.arange(len(self.attack_types))).to_dict()\n",
    "        labels = batch[label_col].map(self.attack_map).map(map_type).values\n",
    "        \n",
    "        del(batch[label_col])\n",
    "        \n",
    "        return np.array(batch), labels\n",
    "    \n",
    "    def get_shape(self):\n",
    "        if self.loaded is False:\n",
    "            self._load_df()\n",
    "        \n",
    "        self.data_shape = self.df.shape\n",
    "        return self.data_shape\n",
    "    \n",
    "    def _load_df(self):\n",
    "        if self.train_test == 'train':\n",
    "            self.df = pd.read_csv(self.train_path) \n",
    "        else:\n",
    "            self.df = pd.read_csv(self.test_path)\n",
    "            \n",
    "        self.index=np.random.randint(0,self.df.shape[0]-1,dtype=np.int32)\n",
    "        self.loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkClassificationEnv(gym.Env, data_cls):\n",
    "    def __init__(self,train_test, attack_map, **kwargs):\n",
    "        data_cls.__init__(self,train_test, attack_map,**kwargs)\n",
    "        self.data_shape = self.get_shape()\n",
    "        self.batch_size = kwargs.get('batch_size', 1) \n",
    "        self.fails_episode = kwargs.get('fails_episode', 10) \n",
    "        \n",
    "        # Gym spaces\n",
    "        self.action_space = spaces.Discrete(len(self.attack_types))\n",
    "        self.observation_space = spaces.Discrete(self.data_shape[0])\n",
    "        \n",
    "        self.observation_len = self.data_shape[1]-1\n",
    "        \n",
    "        self.counter = 0\n",
    "\n",
    "    def _update_state(self):\n",
    "        self.states,self.labels = self.get_batch(self.batch_size)\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.states,self.labels = self.get_batch(self.batch_size)\n",
    "        self.counter = 0\n",
    "        \n",
    "        return self.states\n",
    "    \n",
    "    def _get_rewards(self,actions):\n",
    "        self.reward = 0\n",
    "        if actions == self.labels:\n",
    "            self.reward = 1\n",
    "        else: \n",
    "            self.counter += 1\n",
    "\n",
    "    def step(self,actions):\n",
    "        self._get_rewards(actions)\n",
    "            \n",
    "        self._update_state()\n",
    "\n",
    "        if self.counter >= self.fails_episode:\n",
    "            self.done = True\n",
    "        else:\n",
    "            self.done = False\n",
    "            \n",
    "        return self.states, self.reward, self.done\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def huber_loss(y_true, y_pred, clip_value=1.0):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < clip_value\n",
    "    squared_loss = 0.5 * tf.square(error)\n",
    "    linear_loss = clip_value * (tf.abs(error) - 0.5 * clip_value)\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:33.892684Z",
     "iopub.status.busy": "2023-11-28T14:02:33.892087Z",
     "iopub.status.idle": "2023-11-28T14:02:33.906012Z",
     "shell.execute_reply": "2023-11-28T14:02:33.904944Z",
     "shell.execute_reply.started": "2023-11-28T14:02:33.892638Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:37.423752Z",
     "iopub.status.busy": "2023-11-28T14:02:37.422774Z",
     "iopub.status.idle": "2023-11-28T14:02:47.379183Z",
     "shell.execute_reply": "2023-11-28T14:02:47.377587Z",
     "shell.execute_reply.started": "2023-11-28T14:02:37.423694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/DDQN_model.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/DDQN_model.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m jfile:\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_from_json(json\u001b[38;5;241m.\u001b[39mload(jfile))\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/DDQN_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/VSCode/Hierarchical-Q-Learning-Threat-Hunting/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/DDQN_model.json'"
     ]
    }
   ],
   "source": [
    "with open(\"models/DDQN_model.json\", \"r\") as jfile:\n",
    "    model = model_from_json(json.load(jfile))\n",
    "model.load_weights(\"models/DDQN_model.h5\")\n",
    "\n",
    "\n",
    "model.compile(loss=huber_loss, optimizer=\"sgd\")\n",
    "\n",
    "env = NetworkClassificationEnv('test', label_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:02:47.383534Z",
     "iopub.status.busy": "2023-11-28T14:02:47.382624Z",
     "iopub.status.idle": "2023-11-28T14:04:19.474724Z",
     "shell.execute_reply": "2023-11-28T14:04:19.473562Z",
     "shell.execute_reply.started": "2023-11-28T14:02:47.383478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "total_reward = 0\n",
    "    \n",
    "true_labels = np.zeros(len(env.attack_types),dtype=int)\n",
    "estimated_labels = np.zeros(len(env.attack_types),dtype=int)\n",
    "estimated_correct_labels = np.zeros(len(env.attack_types),dtype=int)\n",
    "\n",
    "states, labels = env.get_full()\n",
    "q = model.predict(states)\n",
    "actions = np.argmax(q, axis=1)        \n",
    "\n",
    "\n",
    "labs, true_labels = np.unique(labels, return_counts=True)\n",
    "\n",
    "for indx,a in enumerate(actions):\n",
    "    estimated_labels[a] +=1              \n",
    "    if a == labels[indx]:\n",
    "        total_reward += 1\n",
    "        estimated_correct_labels[a] += 1\n",
    "\n",
    "\n",
    "Accuracy = estimated_correct_labels / true_labels\n",
    "Mismatch = estimated_labels - true_labels\n",
    "\n",
    "print('\\r\\nTotal reward: {} | Number of samples: {} | Accuracy = {}%'.format(total_reward,\n",
    "      len(states),float(100*total_reward/len(states))))\n",
    "outputs_df = pd.DataFrame(index = env.attack_types,columns = [\"Estimated\",\"Correct\",\"Total\",\"Acuracy\"])\n",
    "for indx,att in enumerate(env.attack_types):\n",
    "    outputs_df.iloc[indx].Estimated = estimated_labels[indx]\n",
    "    outputs_df.iloc[indx].Correct = estimated_correct_labels[indx]\n",
    "    outputs_df.iloc[indx].Total = true_labels[indx]\n",
    "    outputs_df.iloc[indx].Acuracy = Accuracy[indx]*100\n",
    "    outputs_df.iloc[indx].Mismatch = abs(Mismatch[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:04:19.477484Z",
     "iopub.status.busy": "2023-11-28T14:04:19.476285Z",
     "iopub.status.idle": "2023-11-28T14:04:19.499547Z",
     "shell.execute_reply": "2023-11-28T14:04:19.497863Z",
     "shell.execute_reply.started": "2023-11-28T14:04:19.477418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "outputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:04:50.950266Z",
     "iopub.status.busy": "2023-11-28T14:04:50.949486Z",
     "iopub.status.idle": "2023-11-28T14:04:51.413369Z",
     "shell.execute_reply": "2023-11-28T14:04:51.412151Z",
     "shell.execute_reply.started": "2023-11-28T14:04:50.950205Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "width = 0.35\n",
    "pos = np.arange(len(true_labels))\n",
    "p1 = plt.bar(pos, estimated_correct_labels,width,color='g')\n",
    "p1 = plt.bar(pos+width,\n",
    "             (np.abs(estimated_correct_labels-true_labels)),width,\n",
    "             color='r')\n",
    "p2 = plt.bar(pos+width,np.abs(estimated_labels-estimated_correct_labels),width,\n",
    "             bottom=(np.abs(estimated_correct_labels-true_labels)),\n",
    "             color='b')\n",
    "\n",
    "\n",
    "ax.set_xticks(pos+width/2)\n",
    "ax.set_xticklabels(env.attack_types,rotation='vertical')\n",
    "\n",
    "ax.set_title('Test set scores, Acc = {:.2f}'.format(100*total_reward/len(states)))\n",
    "plt.legend(('Correct estimated','False negative','False positive'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('results/ADFA_DDQN.svg', format='svg', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T14:04:51.891211Z",
     "iopub.status.busy": "2023-11-28T14:04:51.890383Z",
     "iopub.status.idle": "2023-11-28T14:04:57.35102Z",
     "shell.execute_reply": "2023-11-28T14:04:57.349664Z",
     "shell.execute_reply.started": "2023-11-28T14:04:51.89117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aggregated_data_test =labels\n",
    "\n",
    "print('Performance measures on Test data')\n",
    "print('Accuracy =  {:.4f}'.format(accuracy_score( aggregated_data_test,actions)))\n",
    "print('F1 =  {:.4f}'.format(f1_score(aggregated_data_test,actions, average='weighted')))\n",
    "print('Precision_score =  {:.4f}'.format(precision_score(aggregated_data_test,actions, average='weighted')))\n",
    "print('recall_score =  {:.4f}'.format(recall_score(aggregated_data_test,actions, average='weighted')))\n",
    "\n",
    "cnf_matrix = confusion_matrix(aggregated_data_test,actions)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=env.attack_types, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.savefig('results/confusion_matrix_DDQN_model.svg', format='svg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"processed_data/train_df.csv\")\n",
    "test_df = pd.read_csv(\"processed_data/test_df.csv\")\n",
    "\n",
    "with open('processed_data/class_weights.json', 'r') as f:\n",
    "    class_weights = json.load(f)\n",
    "with open('processed_data/label_dict.json', 'r') as f:\n",
    "    label_dict = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 902298,
     "sourceId": 1530359,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
