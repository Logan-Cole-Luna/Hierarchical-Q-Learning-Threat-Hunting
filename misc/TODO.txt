- Update Train.py to be up to date w/ overfit.py so overfit.py can be removed

- Update the visuals, eg network flow, transition to plotly?

- Larger data segment similar to how the subset is made in 
    preprocess where it evenly divides the data so its not all benign

- Improve reward function 

- Implement proper Q learning algorithm

- Improve data preprocessing, have the values be better normalized & encoded

- Improve training env, how should we set it up? Implement it so that the model is scaning multiple ports repeatedly 
    looking for change?

- Integrate attention into the Q Learning Model


- Temporal Context with State History: Provide agents with a history of past states to capture temporal dependencies.
- Hierarchical Agent Coordination with Shared Information: Enable high-level agents to influence low-level agents through shared goals or information.
- Proper Deep Q-Learning Enhancements: Implement target networks and experience replay to stabilize and improve training.