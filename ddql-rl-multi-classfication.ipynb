{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1530359,"sourceType":"datasetVersion","datasetId":902298}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-28T15:51:37.654435Z","iopub.execute_input":"2023-11-28T15:51:37.654978Z","iopub.status.idle":"2023-11-28T15:51:38.233541Z","shell.execute_reply.started":"2023-11-28T15:51:37.654942Z","shell.execute_reply":"2023-11-28T15:51:38.232117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:51:38.995928Z","iopub.execute_input":"2023-11-28T15:51:38.997611Z","iopub.status.idle":"2023-11-28T15:51:39.003133Z","shell.execute_reply.started":"2023-11-28T15:51:38.997536Z","shell.execute_reply":"2023-11-28T15:51:39.001956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-14-2018.csv\", low_memory=False)\ndf_d2 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-15-2018.csv\", low_memory=False)\ndf_d3 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-16-2018.csv\", low_memory=False)\ndf_d4 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-20-2018.csv\", low_memory=False)\ndf_d5 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-21-2018.csv\", low_memory=False)\ndf_d6 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-22-2018.csv\", low_memory=False)\ndf_d7 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-23-2018.csv\", low_memory=False)\ndf_d8 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/02-28-2018.csv\", low_memory=False)\ndf_d9 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/03-01-2018.csv\", low_memory=False)\ndf_d10 = pd.read_csv(\"/kaggle/input/ids-intrusion-csv/03-02-2018.csv\", low_memory=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:51:39.611976Z","iopub.execute_input":"2023-11-28T15:51:39.612413Z","iopub.status.idle":"2023-11-28T16:00:41.977385Z","shell.execute_reply.started":"2023-11-28T15:51:39.612383Z","shell.execute_reply":"2023-11-28T16:00:41.976122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_d4.drop(columns=['Flow ID', 'Src IP', 'Src Port', 'Dst IP'], axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:01:31.074348Z","iopub.execute_input":"2023-11-28T16:01:31.074904Z","iopub.status.idle":"2023-11-28T16:01:35.089052Z","shell.execute_reply.started":"2023-11-28T16:01:31.074865Z","shell.execute_reply":"2023-11-28T16:01:35.087484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fix_data_type(df):\n    \n    df = df[df['Dst Port'] != 'Dst Port']\n    \n    df['Dst Port'] = df['Dst Port'].astype(int)\n    df['Protocol'] = df['Protocol'].astype(int)\n    df['Flow Duration'] = df['Flow Duration'].astype(int)\n    df['Tot Fwd Pkts'] = df['Tot Fwd Pkts'].astype(int)\n    df['Tot Bwd Pkts'] = df['Tot Bwd Pkts'].astype(int)\n    df['TotLen Fwd Pkts'] = df['TotLen Fwd Pkts'].astype(int)\n    df['TotLen Bwd Pkts'] = df['TotLen Bwd Pkts'].astype(int)\n    df['Fwd Pkt Len Max'] = df['Fwd Pkt Len Max'].astype(int)\n    df['Fwd Pkt Len Min'] = df['Fwd Pkt Len Min'].astype(int)\n    df['Fwd Pkt Len Mean'] = df['Fwd Pkt Len Mean'].astype(float)\n    df['Fwd Pkt Len Std'] = df['Fwd Pkt Len Std'].astype(float)\n    df['Bwd Pkt Len Max'] = df['Bwd Pkt Len Max'].astype(int)\n    df['Bwd Pkt Len Min'] = df['Bwd Pkt Len Min'].astype(int)\n    df['Bwd Pkt Len Mean'] = df['Bwd Pkt Len Mean'].astype(float)\n    df['Bwd Pkt Len Std'] = df['Bwd Pkt Len Std'].astype(float)\n    df['Flow Byts/s'] = df['Flow Byts/s'].astype(float)\n    df['Flow Pkts/s'] = df['Flow Pkts/s'].astype(float)\n    df['Flow IAT Mean'] = df['Flow IAT Mean'].astype(float)\n    df['Flow IAT Std'] = df['Flow IAT Std'].astype(float)\n    df['Flow IAT Max'] = df['Flow IAT Max'].astype(int)\n    df['Flow IAT Min'] = df['Flow IAT Min'].astype(int)\n    df['Fwd IAT Tot'] = df['Fwd IAT Tot'].astype(int)\n    df['Fwd IAT Mean'] = df['Fwd IAT Mean'].astype(float)\n    df['Fwd IAT Std'] = df['Fwd IAT Std'].astype(float)\n    df['Fwd IAT Max'] = df['Fwd IAT Max'].astype(int)\n    df['Fwd IAT Min'] = df['Fwd IAT Min'].astype(int)\n    df['Bwd IAT Tot'] = df['Bwd IAT Tot'].astype(int)\n    df['Bwd IAT Mean'] = df['Bwd IAT Mean'].astype(float)\n    df['Bwd IAT Std'] = df['Bwd IAT Std'].astype(float)\n    df['Bwd IAT Max'] = df['Bwd IAT Max'].astype(int)\n    df['Bwd IAT Min'] = df['Bwd IAT Min'].astype(int)\n    df['Fwd PSH Flags'] = df['Fwd PSH Flags'].astype(int)\n    df['Bwd PSH Flags'] = df['Bwd PSH Flags'].astype(int)\n    df['Fwd URG Flags'] = df['Fwd URG Flags'].astype(int)\n    df['Bwd URG Flags'] = df['Bwd URG Flags'].astype(int)\n    df['Fwd Header Len'] = df['Fwd Header Len'].astype(int)\n    df['Bwd Header Len'] = df['Bwd Header Len'].astype(int)\n    df['Fwd Pkts/s'] = df['Fwd Pkts/s'].astype(float)\n    df['Bwd Pkts/s'] = df['Bwd Pkts/s'].astype(float)\n    df['Pkt Len Min'] = df['Pkt Len Min'].astype(int)\n    df['Pkt Len Max'] = df['Pkt Len Max'].astype(int)\n    df['Pkt Len Mean'] = df['Pkt Len Mean'].astype(float)\n    df['Pkt Len Std'] = df['Pkt Len Std'].astype(float)\n    df['Pkt Len Var'] = df['Pkt Len Var'].astype(float)\n    df['FIN Flag Cnt'] = df['FIN Flag Cnt'].astype(int)\n    df['SYN Flag Cnt'] = df['SYN Flag Cnt'].astype(int)\n    df['RST Flag Cnt'] = df['RST Flag Cnt'].astype(int)\n    df['PSH Flag Cnt'] = df['PSH Flag Cnt'].astype(int)\n    df['ACK Flag Cnt'] = df['ACK Flag Cnt'].astype(int)\n    df['URG Flag Cnt'] = df['URG Flag Cnt'].astype(int)\n    df['CWE Flag Count'] = df['CWE Flag Count'].astype(int)\n    df['ECE Flag Cnt'] = df['ECE Flag Cnt'].astype(int)\n    df['Down/Up Ratio'] = df['Down/Up Ratio'].astype(int)\n    df['Pkt Size Avg'] = df['Pkt Size Avg'].astype(float)\n    df['Fwd Seg Size Avg'] = df['Fwd Seg Size Avg'].astype(float)\n    df['Bwd Seg Size Avg'] = df['Bwd Seg Size Avg'].astype(float)\n    df['Fwd Byts/b Avg'] = df['Fwd Byts/b Avg'].astype(int)\n    df['Fwd Pkts/b Avg'] = df['Fwd Pkts/b Avg'].astype(int)\n    df['Fwd Blk Rate Avg'] = df['Fwd Blk Rate Avg'].astype(int)\n    df['Bwd Byts/b Avg'] = df['Bwd Byts/b Avg'].astype(int)\n    df['Bwd Pkts/b Avg'] = df['Bwd Pkts/b Avg'].astype(int)\n    df['Bwd Blk Rate Avg'] = df['Bwd Blk Rate Avg'].astype(int)\n    df['Subflow Fwd Pkts'] = df['Subflow Fwd Pkts'].astype(int)\n    df['Subflow Fwd Byts'] = df['Subflow Fwd Byts'].astype(int)\n    df['Subflow Bwd Pkts'] = df['Subflow Bwd Pkts'].astype(int)\n    df['Subflow Bwd Byts'] = df['Subflow Bwd Byts'].astype(int)\n    df['Init Fwd Win Byts'] = df['Init Fwd Win Byts'].astype(int)\n    df['Init Bwd Win Byts'] = df['Init Bwd Win Byts'].astype(int)\n    df['Fwd Act Data Pkts'] = df['Fwd Act Data Pkts'].astype(int)\n    df['Fwd Seg Size Min'] = df['Fwd Seg Size Min'].astype(int)\n    df['Active Mean'] = df['Active Mean'].astype(float)\n    df['Active Std'] = df['Active Std'].astype(float)\n    df['Active Max'] = df['Active Max'].astype(int)\n    df['Active Min'] = df['Active Min'].astype(int)\n    df['Idle Mean'] = df['Idle Mean'].astype(float)\n    df['Idle Std'] = df['Idle Std'].astype(float)\n    df['Idle Max'] = df['Idle Max'].astype(int)\n    df['Idle Min'] = df['Idle Min'].astype(int)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:01:35.09128Z","iopub.execute_input":"2023-11-28T16:01:35.092191Z","iopub.status.idle":"2023-11-28T16:01:35.126598Z","shell.execute_reply.started":"2023-11-28T16:01:35.092141Z","shell.execute_reply":"2023-11-28T16:01:35.124857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = fix_data_type(df_d1)\ndf_d2 = fix_data_type(df_d2)\ndf_d3 = fix_data_type(df_d3)\ndf_d4 = fix_data_type(df_d4)\ndf_d5 = fix_data_type(df_d5)\ndf_d6 = fix_data_type(df_d6)\ndf_d7 = fix_data_type(df_d7)\ndf_d8 = fix_data_type(df_d8)\ndf_d9 = fix_data_type(df_d9)\ndf_d10 = fix_data_type(df_d10)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:01:35.128496Z","iopub.execute_input":"2023-11-28T16:01:35.12902Z","iopub.status.idle":"2023-11-28T16:02:23.155574Z","shell.execute_reply.started":"2023-11-28T16:01:35.12898Z","shell.execute_reply":"2023-11-28T16:02:23.154068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_infinate_null(df):\n    print (df.shape)\n\n    # replace infinity value as null value\n    df = df.replace([\"Infinity\", \"infinity\"], np.inf)\n    df = df.replace([np.inf, -np.inf], np.nan)\n\n    # drop all null values\n    df.dropna(inplace=True)\n\n    print (df.shape)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:02:23.159216Z","iopub.execute_input":"2023-11-28T16:02:23.160436Z","iopub.status.idle":"2023-11-28T16:02:23.168072Z","shell.execute_reply.started":"2023-11-28T16:02:23.160389Z","shell.execute_reply":"2023-11-28T16:02:23.166709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = drop_infinate_null(df_d1)\ndf_d2 = drop_infinate_null(df_d2)\ndf_d3 = drop_infinate_null(df_d3)\ndf_d4 = drop_infinate_null(df_d4)\ndf_d5 = drop_infinate_null(df_d5)\ndf_d6 = drop_infinate_null(df_d6)\ndf_d7 = drop_infinate_null(df_d7)\ndf_d8 = drop_infinate_null(df_d8)\ndf_d9 = drop_infinate_null(df_d9)\ndf_d10 = drop_infinate_null(df_d10)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:02:23.170021Z","iopub.execute_input":"2023-11-28T16:02:23.17102Z","iopub.status.idle":"2023-11-28T16:03:39.148264Z","shell.execute_reply.started":"2023-11-28T16:02:23.170967Z","shell.execute_reply":"2023-11-28T16:03:39.146556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_unnecessary_column(df): \n    df.drop(columns=\"Timestamp\", inplace=True)\n    print (df.shape)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:03:39.150308Z","iopub.execute_input":"2023-11-28T16:03:39.150882Z","iopub.status.idle":"2023-11-28T16:03:39.158007Z","shell.execute_reply.started":"2023-11-28T16:03:39.150842Z","shell.execute_reply":"2023-11-28T16:03:39.156505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = drop_unnecessary_column(df_d1)\ndf_d2 = drop_unnecessary_column(df_d2)\ndf_d3 = drop_unnecessary_column(df_d3)\ndf_d4 = drop_unnecessary_column(df_d4)\ndf_d5 = drop_unnecessary_column(df_d5)\ndf_d6 = drop_unnecessary_column(df_d6)\ndf_d7 = drop_unnecessary_column(df_d7)\ndf_d8 = drop_unnecessary_column(df_d8)\ndf_d9 = drop_unnecessary_column(df_d9)\ndf_d10 = drop_unnecessary_column(df_d10)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:03:39.159769Z","iopub.execute_input":"2023-11-28T16:03:39.160185Z","iopub.status.idle":"2023-11-28T16:03:45.124072Z","shell.execute_reply.started":"2023-11-28T16:03:39.160151Z","shell.execute_reply":"2023-11-28T16:03:45.122969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_binary_label(df):\n    # encode the target feature\n    df['Threat'] = df['Label'].apply(lambda x: \"Benign\" if x == 'Benign' else \"Malicious\")\n    print(df['Threat'].unique())\n    print(df['Threat'].value_counts())\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:03:45.126167Z","iopub.execute_input":"2023-11-28T16:03:45.126604Z","iopub.status.idle":"2023-11-28T16:03:45.13395Z","shell.execute_reply.started":"2023-11-28T16:03:45.126566Z","shell.execute_reply":"2023-11-28T16:03:45.132361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = generate_binary_label(df_d1)\ndf_d2 = generate_binary_label(df_d2)\ndf_d3 = generate_binary_label(df_d3)\ndf_d4 = generate_binary_label(df_d4)\ndf_d5 = generate_binary_label(df_d5)\ndf_d6 = generate_binary_label(df_d6)\ndf_d7 = generate_binary_label(df_d7)\ndf_d8 = generate_binary_label(df_d8)\ndf_d9 = generate_binary_label(df_d9)\ndf_d10 = generate_binary_label(df_d10)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:03:45.1403Z","iopub.execute_input":"2023-11-28T16:03:45.140972Z","iopub.status.idle":"2023-11-28T16:03:53.887382Z","shell.execute_reply.started":"2023-11-28T16:03:45.140932Z","shell.execute_reply":"2023-11-28T16:03:53.885783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] \n    for col in props.columns:\n        if props[col].dtype != object:  \n\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n            \n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            else:\n                props[col] = props[col].astype(np.float32)\n    \n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return props, NAlist","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:03:53.889844Z","iopub.execute_input":"2023-11-28T16:03:53.890558Z","iopub.status.idle":"2023-11-28T16:03:53.910446Z","shell.execute_reply.started":"2023-11-28T16:03:53.890501Z","shell.execute_reply":"2023-11-28T16:03:53.908467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1, _ = reduce_mem_usage(df_d1)\ndf_d2, _ = reduce_mem_usage(df_d2)\ndf_d3, _ = reduce_mem_usage(df_d3)\ndf_d4, _ = reduce_mem_usage(df_d4)\ndf_d5, _ = reduce_mem_usage(df_d5)\ndf_d6, _ = reduce_mem_usage(df_d6)\ndf_d7, _ = reduce_mem_usage(df_d7)\ndf_d8, _ = reduce_mem_usage(df_d8)\ndf_d9, _ = reduce_mem_usage(df_d9)\ndf_d10, _ = reduce_mem_usage(df_d10)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:03:53.912964Z","iopub.execute_input":"2023-11-28T16:03:53.913534Z","iopub.status.idle":"2023-11-28T16:04:20.076124Z","shell.execute_reply.started":"2023-11-28T16:03:53.913478Z","shell.execute_reply":"2023-11-28T16:04:20.074752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## https://www.researchgate.net/figure/Attack-Types-in-CSE-CIC-IDS2018-dataset_tbl1_333894962\n\nmapping= {'SSH-Bruteforce': 'Brute-force',\n          'FTP-BruteForce': 'Brute-force',\n          ################ Brute-force \n          \n          'Brute Force -XSS': 'Web attack',\n          'Brute Force -Web': 'Web attack',\n          'SQL Injection': 'Web attack',\n          ################ Web attack \n          \n          'DoS attacks-Hulk': 'DoS attack',\n          'DoS attacks-SlowHTTPTest': 'DoS attack',\n          'DoS attacks-Slowloris': 'DoS attack',\n          'DoS attacks-GoldenEye': 'DoS attack',\n          ################ DoS attack \n          \n          'DDOS attack-HOIC': 'DDoS attack',\n          'DDOS attack-LOIC-UDP': 'DDoS attack',\n          'DDoS attacks-LOIC-HTTP': 'DDoS attack',\n          ################ DDoS attack \n          \n          'Bot': 'Botnet',\n          ################ Botnet \n          \n          'Infilteration': 'Infilteration',\n          ################ Infilteration \n          \n          'Benign': 'Benign',\n          'Label': 'Benign',\n          ################ Infilteration \n    }\n\ndef transform_multi_label(df):\n    print(df['Label'].value_counts())\n    df['Label'] = df['Label'].map(mapping) \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:04:20.08096Z","iopub.execute_input":"2023-11-28T16:04:20.081438Z","iopub.status.idle":"2023-11-28T16:04:20.092662Z","shell.execute_reply.started":"2023-11-28T16:04:20.081397Z","shell.execute_reply":"2023-11-28T16:04:20.090914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = transform_multi_label(df_d1)\ndf_d2 = transform_multi_label(df_d2)\ndf_d3 = transform_multi_label(df_d3)\ndf_d4 = transform_multi_label(df_d4)\ndf_d5 = transform_multi_label(df_d5)\ndf_d6 = transform_multi_label(df_d6)\ndf_d7 = transform_multi_label(df_d7)\ndf_d8 = transform_multi_label(df_d8)\ndf_d9 = transform_multi_label(df_d9)\ndf_d10 = transform_multi_label(df_d10)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:04:20.095381Z","iopub.execute_input":"2023-11-28T16:04:20.096005Z","iopub.status.idle":"2023-11-28T16:04:25.862088Z","shell.execute_reply.started":"2023-11-28T16:04:20.095949Z","shell.execute_reply":"2023-11-28T16:04:25.860643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\n\ndef balance_data(df):\n    X=df.drop([\"Label\"], axis=1)\n    y=df[\"Label\"]\n\n    rus = RandomUnderSampler()\n    X_balanced, y_balanced = rus.fit_resample(X, y) \n\n    df = pd.concat([X_balanced, y_balanced], axis=1)\n    del X, y, X_balanced, y_balanced\n    print (df.shape)\n    print(df['Label'].value_counts())\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:04:25.864033Z","iopub.execute_input":"2023-11-28T16:04:25.864801Z","iopub.status.idle":"2023-11-28T16:04:25.875216Z","shell.execute_reply.started":"2023-11-28T16:04:25.864748Z","shell.execute_reply":"2023-11-28T16:04:25.873666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_d1 = balance_data(df_d1)\ndf_d2 = balance_data(df_d2)\ndf_d3 = balance_data(df_d3)\ndf_d4 = balance_data(df_d4)\ndf_d5 = balance_data(df_d5)\ndf_d6 = balance_data(df_d6)\ndf_d7 = balance_data(df_d7)\ndf_d8 = balance_data(df_d8)\ndf_d9 = balance_data(df_d9)\ndf_d10 = balance_data(df_d10)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:04:25.877508Z","iopub.execute_input":"2023-11-28T16:04:25.878431Z","iopub.status.idle":"2023-11-28T16:06:43.336007Z","shell.execute_reply.started":"2023-11-28T16:04:25.878381Z","shell.execute_reply":"2023-11-28T16:06:43.334399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_all = pd.concat([df_d1, df_d2], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d1, df_d2\n\ndf_all = pd.concat([df_all, df_d3], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d3\n\ndf_all = pd.concat([df_all, df_d4], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d4\n\ndf_all = pd.concat([df_all, df_d5], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d5\n\ndf_all = pd.concat([df_all, df_d6], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d6\n\ndf_all = pd.concat([df_all, df_d7], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d7\n\ndf_all = pd.concat([df_all, df_d8], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d8\n\ndf_all = pd.concat([df_all, df_d9], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d9\n\ndf_all = pd.concat([df_all, df_d10], axis=0)\ndf_all.reset_index(drop=True, inplace=True)\ndel df_d10","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:43.339026Z","iopub.execute_input":"2023-11-28T16:06:43.339638Z","iopub.status.idle":"2023-11-28T16:06:45.910385Z","shell.execute_reply.started":"2023-11-28T16:06:43.339584Z","shell.execute_reply":"2023-11-28T16:06:45.908914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_all = df_d4\n# del df_d4","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:45.912201Z","iopub.execute_input":"2023-11-28T16:06:45.912594Z","iopub.status.idle":"2023-11-28T16:06:45.918807Z","shell.execute_reply.started":"2023-11-28T16:06:45.912562Z","shell.execute_reply":"2023-11-28T16:06:45.917318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_all['Label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:45.920614Z","iopub.execute_input":"2023-11-28T16:06:45.921003Z","iopub.status.idle":"2023-11-28T16:06:46.498169Z","shell.execute_reply.started":"2023-11-28T16:06:45.92097Z","shell.execute_reply":"2023-11-28T16:06:46.496804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attack_df = df_all[df_all[\"Threat\"] != \"Benign\"]\n# normal_df = df_all[df_all[\"Threat\"] == \"Benign\"].sample(n=len(attack_df))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:46.499667Z","iopub.execute_input":"2023-11-28T16:06:46.500071Z","iopub.status.idle":"2023-11-28T16:06:46.511801Z","shell.execute_reply.started":"2023-11-28T16:06:46.500038Z","shell.execute_reply":"2023-11-28T16:06:46.510319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_all = pd.concat([attack_df, normal_df], axis=0)\n# del attack_df, normal_df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:46.516524Z","iopub.execute_input":"2023-11-28T16:06:46.518087Z","iopub.status.idle":"2023-11-28T16:06:46.52477Z","shell.execute_reply.started":"2023-11-28T16:06:46.518031Z","shell.execute_reply":"2023-11-28T16:06:46.523141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nvariances = df_all.var(numeric_only=True)\nconstant_columns = variances[variances == 0].index\ndf_all = df_all.drop(constant_columns, axis=1)\n\nprint(constant_columns)\nprint (df_all.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:46.52644Z","iopub.execute_input":"2023-11-28T16:06:46.52728Z","iopub.status.idle":"2023-11-28T16:06:51.479566Z","shell.execute_reply.started":"2023-11-28T16:06:46.527234Z","shell.execute_reply":"2023-11-28T16:06:51.478629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nduplicates = set()\nfor i in range(0, len(df_all.columns)):\n    col1 = df_all.columns[i]\n    for j in range(i+1, len(df_all.columns)):\n        col2 = df_all.columns[j]\n        if(df_all[col1].equals(df_all[col2])):\n            duplicates.add(col2)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:51.484569Z","iopub.execute_input":"2023-11-28T16:06:51.485688Z","iopub.status.idle":"2023-11-28T16:06:56.840444Z","shell.execute_reply.started":"2023-11-28T16:06:51.485638Z","shell.execute_reply":"2023-11-28T16:06:56.837242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (duplicates)\ndf_all.drop(duplicates, axis=1, inplace=True)\nprint (df_all.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:56.844457Z","iopub.execute_input":"2023-11-28T16:06:56.845835Z","iopub.status.idle":"2023-11-28T16:06:59.098117Z","shell.execute_reply.started":"2023-11-28T16:06:56.845744Z","shell.execute_reply":"2023-11-28T16:06:59.09681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\n# pearson correlation heatmap\nplt.figure(figsize=(70, 70))\ncorr = df_all.corr(numeric_only=True)\nsns.heatmap(corr, annot=True, cmap='RdBu', vmin=-1, vmax=1, square=True) # annot=True\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:06:59.101904Z","iopub.execute_input":"2023-11-28T16:06:59.102963Z","iopub.status.idle":"2023-11-28T16:08:04.232862Z","shell.execute_reply.started":"2023-11-28T16:06:59.102896Z","shell.execute_reply":"2023-11-28T16:08:04.231138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncorrelated_col = set()\nis_correlated = [True] * len(corr.columns)\nthreshold = 0.90\nfor i in range (len(corr.columns)):\n    if(is_correlated[i]):\n        for j in range(i):\n            if (np.abs(corr.iloc[i, j]) >= threshold) and (is_correlated[j]):\n                colname = corr.columns[j]\n                is_correlated[j]=False\n                correlated_col.add(colname)\n\nprint(correlated_col)\nprint(len(correlated_col))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:04.236052Z","iopub.execute_input":"2023-11-28T16:08:04.237094Z","iopub.status.idle":"2023-11-28T16:08:04.328598Z","shell.execute_reply.started":"2023-11-28T16:08:04.237023Z","shell.execute_reply":"2023-11-28T16:08:04.326856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_all.drop(correlated_col, axis=1, inplace=True)\nprint (df_all.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:04.330207Z","iopub.execute_input":"2023-11-28T16:08:04.330666Z","iopub.status.idle":"2023-11-28T16:08:05.652904Z","shell.execute_reply.started":"2023-11-28T16:08:04.330629Z","shell.execute_reply":"2023-11-28T16:08:05.651515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# pearson correlation heatmap\nplt.figure(figsize=(70, 70))\ncorr = df_all.corr(numeric_only=True)\nsns.heatmap(corr, annot=True, cmap='RdBu', vmin=-1, vmax=1, square=True) # annot=True\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:05.655061Z","iopub.execute_input":"2023-11-28T16:08:05.656005Z","iopub.status.idle":"2023-11-28T16:08:34.491154Z","shell.execute_reply.started":"2023-11-28T16:08:05.655942Z","shell.execute_reply":"2023-11-28T16:08:34.48933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_col = \"Label\"","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:34.493075Z","iopub.execute_input":"2023-11-28T16:08:34.494467Z","iopub.status.idle":"2023-11-28T16:08:34.500283Z","shell.execute_reply.started":"2023-11-28T16:08:34.49442Z","shell.execute_reply":"2023-11-28T16:08:34.499002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = list(df_all.columns)\nfeature_cols","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:34.502185Z","iopub.execute_input":"2023-11-28T16:08:34.502595Z","iopub.status.idle":"2023-11-28T16:08:34.517864Z","shell.execute_reply.started":"2023-11-28T16:08:34.502562Z","shell.execute_reply":"2023-11-28T16:08:34.51556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_col = 'Label'\n\nfeature_cols.remove(\"Threat\")\nfeature_cols.remove(label_col)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:34.519294Z","iopub.execute_input":"2023-11-28T16:08:34.519762Z","iopub.status.idle":"2023-11-28T16:08:34.528516Z","shell.execute_reply.started":"2023-11-28T16:08:34.519714Z","shell.execute_reply":"2023-11-28T16:08:34.526958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(df_all, test_size=0.2, random_state=2, shuffle=True, stratify=df_all[label_col])\n\ndel df_all ","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:39.178355Z","iopub.execute_input":"2023-11-28T16:08:39.178811Z","iopub.status.idle":"2023-11-28T16:08:55.02889Z","shell.execute_reply.started":"2023-11-28T16:08:39.178772Z","shell.execute_reply":"2023-11-28T16:08:55.027499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler, MinMaxScaler\n\nminmax_scaler = MinMaxScaler()\ntrain_df[feature_cols] = minmax_scaler.fit_transform(train_df[feature_cols])\ntest_df[feature_cols] = minmax_scaler.transform(test_df[feature_cols])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:08:55.030631Z","iopub.execute_input":"2023-11-28T16:08:55.031144Z","iopub.status.idle":"2023-11-28T16:08:59.056176Z","shell.execute_reply.started":"2023-11-28T16:08:55.031107Z","shell.execute_reply":"2023-11-28T16:08:59.054822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"order_label_list = list(np.unique(train_df[label_col]))\norder_label_list","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:09:56.250819Z","iopub.execute_input":"2023-11-28T16:09:56.25186Z","iopub.status.idle":"2023-11-28T16:10:01.673412Z","shell.execute_reply.started":"2023-11-28T16:09:56.251789Z","shell.execute_reply":"2023-11-28T16:10:01.671952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 classes=order_label_list,\n                                                 y=train_df[label_col].values)\n\nclass_weights = {k: v for k,v in enumerate(class_weights)}\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:12:07.029648Z","iopub.execute_input":"2023-11-28T16:12:07.030071Z","iopub.status.idle":"2023-11-28T16:12:08.197125Z","shell.execute_reply.started":"2023-11-28T16:12:07.030032Z","shell.execute_reply":"2023-11-28T16:12:08.195643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json \n    \nwith open(\"class_weights.json\", \"w\") as outfile: \n    json.dump(class_weights, outfile)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:12:43.10536Z","iopub.execute_input":"2023-11-28T16:12:43.105929Z","iopub.status.idle":"2023-11-28T16:12:43.114083Z","shell.execute_reply.started":"2023-11-28T16:12:43.105889Z","shell.execute_reply":"2023-11-28T16:12:43.112509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json \n\nlabel_dict = {v:v for v in order_label_list}\n    \nwith open(\"label_dict.json\", \"w\") as outfile: \n    json.dump(label_dict, outfile)\n\n\n    label_dict","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:12:47.093148Z","iopub.execute_input":"2023-11-28T16:12:47.094387Z","iopub.status.idle":"2023-11-28T16:12:47.100798Z","shell.execute_reply.started":"2023-11-28T16:12:47.094346Z","shell.execute_reply":"2023-11-28T16:12:47.099636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = [order_label_list.index(k) for k in train_df[label_col]]\ny_test = [order_label_list.index(k) for k in test_df[label_col]]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:12:48.869188Z","iopub.execute_input":"2023-11-28T16:12:48.869697Z","iopub.status.idle":"2023-11-28T16:12:50.184974Z","shell.execute_reply.started":"2023-11-28T16:12:48.869659Z","shell.execute_reply":"2023-11-28T16:12:50.183637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\n\nmodel = XGBClassifier(n_estimators=100)\n%time\nmodel.fit(train_df[feature_cols].values, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:12:51.180907Z","iopub.execute_input":"2023-11-28T16:12:51.181426Z","iopub.status.idle":"2023-11-28T16:18:13.01896Z","shell.execute_reply.started":"2023-11-28T16:12:51.181386Z","shell.execute_reply":"2023-11-28T16:18:13.017447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_df[feature_cols].values)\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:18:13.021532Z","iopub.execute_input":"2023-11-28T16:18:13.022116Z","iopub.status.idle":"2023-11-28T16:18:21.115477Z","shell.execute_reply.started":"2023-11-28T16:18:13.022075Z","shell.execute_reply":"2023-11-28T16:18:21.11422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ext=pd.DataFrame(model.feature_importances_,columns=[\"extratrees_importance\"])\next = ext.sort_values(['extratrees_importance'], ascending=False)\nfeature_index = [feature_cols[i] for i in list(ext.index)]\next[\"Feature_Name\"] = feature_index\next","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:18:21.117071Z","iopub.execute_input":"2023-11-28T16:18:21.117585Z","iopub.status.idle":"2023-11-28T16:18:21.139194Z","shell.execute_reply.started":"2023-11-28T16:18:21.117532Z","shell.execute_reply":"2023-11-28T16:18:21.137802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\n\nseletor_model = SelectFromModel(model, prefit=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:18:21.141658Z","iopub.execute_input":"2023-11-28T16:18:21.142061Z","iopub.status.idle":"2023-11-28T16:18:21.207225Z","shell.execute_reply.started":"2023-11-28T16:18:21.142028Z","shell.execute_reply":"2023-11-28T16:18:21.205707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features = list(seletor_model.get_feature_names_out(input_features=feature_cols))\nselected_features","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:18:21.209322Z","iopub.execute_input":"2023-11-28T16:18:21.210405Z","iopub.status.idle":"2023-11-28T16:18:21.224784Z","shell.execute_reply.started":"2023-11-28T16:18:21.210365Z","shell.execute_reply":"2023-11-28T16:18:21.223382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\n\nmodel = XGBClassifier(n_estimators=100)\n%time\nmodel.fit(train_df[selected_features].values, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:18:21.226609Z","iopub.execute_input":"2023-11-28T16:18:21.227422Z","iopub.status.idle":"2023-11-28T16:21:22.983326Z","shell.execute_reply.started":"2023-11-28T16:18:21.227372Z","shell.execute_reply":"2023-11-28T16:21:22.981841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_df[selected_features].values)\nprint(classification_report(y_test, y_pred))\n\ndel y_pred, y_test, y_train","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:21:22.985191Z","iopub.execute_input":"2023-11-28T16:21:22.985634Z","iopub.status.idle":"2023-11-28T16:21:30.703662Z","shell.execute_reply.started":"2023-11-28T16:21:22.985593Z","shell.execute_reply":"2023-11-28T16:21:30.70215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[feature_cols+[label_col]].to_csv(\"train_df.csv\",index=False)\ntest_df[feature_cols+[label_col]].to_csv(\"test_df.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:39:11.987611Z","iopub.execute_input":"2023-11-28T16:39:11.988205Z","iopub.status.idle":"2023-11-28T16:43:33.366934Z","shell.execute_reply.started":"2023-11-28T16:39:11.988167Z","shell.execute_reply":"2023-11-28T16:43:33.365639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_df, test_df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:43:33.369701Z","iopub.execute_input":"2023-11-28T16:43:33.370955Z","iopub.status.idle":"2023-11-28T16:43:33.383868Z","shell.execute_reply.started":"2023-11-28T16:43:33.37091Z","shell.execute_reply":"2023-11-28T16:43:33.382361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open('label_dict.json') as json_file:\n    label_dict = json.load(json_file)\n\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:43:33.385595Z","iopub.execute_input":"2023-11-28T16:43:33.386043Z","iopub.status.idle":"2023-11-28T16:43:33.402173Z","shell.execute_reply.started":"2023-11-28T16:43:33.386007Z","shell.execute_reply":"2023-11-28T16:43:33.400491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open('class_weights.json') as json_file:\n    class_weights = json.load(json_file)\n\nclass_weights","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:43:33.406204Z","iopub.execute_input":"2023-11-28T16:43:33.406853Z","iopub.status.idle":"2023-11-28T16:43:33.418057Z","shell.execute_reply.started":"2023-11-28T16:43:33.406812Z","shell.execute_reply":"2023-11-28T16:43:33.41639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport os\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input\nfrom keras import optimizers\nimport keras.backend as K\nimport logging.config\nfrom gym import  spaces\nimport gym\nimport json\nimport sys\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:46.890508Z","iopub.execute_input":"2023-11-28T16:55:46.891135Z","iopub.status.idle":"2023-11-28T16:55:46.900595Z","shell.execute_reply.started":"2023-11-28T16:55:46.891092Z","shell.execute_reply":"2023-11-28T16:55:46.899217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class data_cls:\n    def __init__(self, train_test, attack_map, **kwargs):\n        self.train_test = train_test\n        \n        if self.train_test == 'train':\n            self.train_path = \"train_df.csv\"\n        else:\n            self.test_path = \"test_df.csv\"\n\n        self.attack_map =   attack_map \n        self.attack_types = list(attack_map.keys())\n        \n        self.loaded = False\n        \n    \n    def get_batch(self, batch_size=100):\n        \n        if self.loaded is False:\n            self._load_df()\n            \n        indexes = list(range(self.index,self.index+batch_size))    \n        if max(indexes)>self.data_shape[0]-1:\n            dif = max(indexes)-self.data_shape[0]\n            indexes[len(indexes)-dif-1:len(indexes)] = list(range(dif+1))\n            self.index=batch_size-dif\n            batch = self.df.iloc[indexes]\n        else: \n            batch = self.df.iloc[indexes]\n            self.index += batch_size    \n        \n        map_type = pd.Series(index=self.attack_types,data=np.arange(len(self.attack_types))).to_dict()\n        labels = batch[label_col].map(self.attack_map).map(map_type).values\n        del(batch[label_col])\n            \n        return np.array(batch),labels\n    \n    def get_full(self):\n\n        self._load_df()\n        \n        batch = self.df\n        map_type = pd.Series(index=self.attack_types,data=np.arange(len(self.attack_types))).to_dict()\n        labels = batch[label_col].map(self.attack_map).map(map_type).values\n        \n        del(batch[label_col])\n        \n        return np.array(batch), labels\n    \n    def get_shape(self):\n        if self.loaded is False:\n            self._load_df()\n        \n        self.data_shape = self.df.shape\n        return self.data_shape\n    \n    def _load_df(self):\n        if self.train_test == 'train':\n            self.df = pd.read_csv(self.train_path) \n        else:\n            self.df = pd.read_csv(self.test_path)\n            \n        self.index=np.random.randint(0,self.df.shape[0]-1,dtype=np.int32)\n        self.loaded = True","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:47.485652Z","iopub.execute_input":"2023-11-28T16:55:47.48638Z","iopub.status.idle":"2023-11-28T16:55:47.504222Z","shell.execute_reply.started":"2023-11-28T16:55:47.486338Z","shell.execute_reply":"2023-11-28T16:55:47.503139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NetworkClassificationEnv(gym.Env, data_cls):\n    def __init__(self,train_test, attack_map, **kwargs):\n        data_cls.__init__(self,train_test, attack_map,**kwargs)\n        self.data_shape = self.get_shape()\n        self.batch_size = kwargs.get('batch_size', 1) \n        self.fails_episode = kwargs.get('fails_episode', 10) \n        \n        # Gym spaces\n        self.action_space = spaces.Discrete(len(self.attack_types))\n        self.observation_space = spaces.Discrete(self.data_shape[0])\n        \n        self.observation_len = self.data_shape[1]-1\n        \n        self.counter = 0\n\n    def _update_state(self):\n        self.states,self.labels = self.get_batch(self.batch_size)\n        \n\n    def reset(self):\n        self.states,self.labels = self.get_batch(self.batch_size)\n        self.counter = 0\n        \n        return self.states\n    \n    def _get_rewards(self,actions):\n        self.reward = 0\n        if actions == self.labels:\n            self.reward = 1\n        else: \n            self.counter += 1\n\n    def step(self,actions):\n        self._get_rewards(actions)\n            \n        self._update_state()\n\n        if self.counter >= self.fails_episode:\n            self.done = True\n        else:\n            self.done = False\n            \n        return self.states, self.reward, self.done\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:47.506249Z","iopub.execute_input":"2023-11-28T16:55:47.506926Z","iopub.status.idle":"2023-11-28T16:55:47.522986Z","shell.execute_reply.started":"2023-11-28T16:55:47.506886Z","shell.execute_reply":"2023-11-28T16:55:47.521501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def huber_loss(y_true, y_pred, clip_value=1):\n    assert clip_value > 0.\n\n    x = y_true - y_pred\n    if np.isinf(clip_value):\n        return .5 * K.square(x)\n\n    condition = K.abs(x) < clip_value\n    squared_loss = .5 * K.square(x)\n    linear_loss = clip_value * (K.abs(x) - .5 * clip_value)\n    \n    if K.backend() == 'tensorflow':\n        import tensorflow as tf\n        if hasattr(tf, 'select'):\n            return tf.select(condition, squared_loss, linear_loss)\n        else:\n            return tf.where(condition, squared_loss, linear_loss)\n    else:\n        raise RuntimeError('Unknown backend \"{}\".'.format(K.backend()))\n\nimport keras.losses\nkeras.losses.huber_loss = huber_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:47.5254Z","iopub.execute_input":"2023-11-28T16:55:47.525902Z","iopub.status.idle":"2023-11-28T16:55:47.537347Z","shell.execute_reply.started":"2023-11-28T16:55:47.525863Z","shell.execute_reply":"2023-11-28T16:55:47.536002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class QNetwork():\n    def __init__(self,obs_size,num_actions, hidden_dense_layer_dict = {\"Dense_1\": {\"Size\": 100}}, learning_rate=0.001):\n        self.model = Sequential()\n        \n        self.model.add(Input(shape=(obs_size,)))\n\n        for key, value in hidden_dense_layer_dict.items():\n            self.model.add(Dense(value[\"Size\"], activation='relu', name=key))\n\n        self.model.add(Dense(num_actions))\n        \n        optimizer = optimizers.Adam(learning_rate)\n        self.model.compile(loss=huber_loss,optimizer=optimizer)\n\n    def predict(self,state,batch_size=1):\n        return self.model.predict(state,batch_size=batch_size, verbose=0)\n\n    def update(self, states, q):\n        loss = self.model.train_on_batch(states, q, class_weight=class_weights)\n        return loss\n\nclass Policy:\n    def __init__(self, num_actions, estimator):\n        self.num_actions = num_actions\n        self.estimator = estimator\n    \nclass Epsilon_greedy(Policy):\n    def __init__(self,estimator ,num_actions,epsilon,decay_rate, epoch_length):\n        Policy.__init__(self, num_actions, estimator)\n        self.name = \"Epsilon Greedy\"\n        if (epsilon is None or epsilon < 0 or epsilon > 1):\n            print(\"EpsilonGreedy: Invalid value of epsilon\", flush = True)\n            sys.exit(0)\n        self.epsilon = epsilon\n        self.step_counter = 0\n        self.epoch_length = epoch_length\n        self.decay_rate = decay_rate\n        self.epsilon_decay = True\n        \n    def get_actions(self,states):\n        if np.random.rand() <= self.epsilon:\n            actions = np.random.randint(0, self.num_actions,states.shape[0])\n        else:\n            self.Q = self.estimator.predict(states,states.shape[0])\n\n            actions = []\n            for row in range(self.Q.shape[0]):\n                best_actions = np.argwhere(self.Q[row] == np.amax(self.Q[row]))\n                actions.append(best_actions[np.random.choice(len(best_actions))].item())\n            \n        self.step_counter += 1 \n\n        if self.epsilon_decay:\n            if self.step_counter % self.epoch_length == 0:\n                self.epsilon = max(.01, self.epsilon * self.decay_rate**self.step_counter)\n            \n        return actions\n\nclass Agent(object):   \n    def __init__(self, actions, obs_size, policy=\"EpsilonGreedy\", **kwargs):\n        \n        self.actions = actions\n        self.num_actions = len(actions)\n        self.obs_size = obs_size\n        \n        self.epsilon = kwargs.get('epsilon', 1)\n        self.gamma = kwargs.get('gamma', 0.001)\n        self.minibatch_size = kwargs.get('minibatch_size', 2)\n        self.epoch_length = kwargs.get('epoch_length', 100)\n        self.decay_rate = kwargs.get('decay_rate',0.99)\n        self.exp_rep = kwargs.get('exp_rep',True)\n        \n        if self.exp_rep:\n            self.memory = ReplayMemory(self.obs_size, kwargs.get('mem_size', 10))\n        \n        self.ddqn_time = 100\n        self.ddqn_update = self.ddqn_time\n\n        self.model_network = QNetwork(self.obs_size, \n                                      self.num_actions,\n                                      kwargs.get('hidden_dense_layer_dict', {\"Dense_1\": {\"Size\": 100}}),\n                                      kwargs.get('learning_rate', 0.001))\n        \n        self.target_model_network = QNetwork(self.obs_size, self.num_actions,\n                                             kwargs.get('hidden_dense_layer_dict', {\"Dense_1\": {\"Size\": 100}}),\n                                             kwargs.get('learning_rate', 0.001))\n        \n        self.target_model_network.model.set_weights(self.model_network.model.get_weights()) \n        \n        if policy == \"EpsilonGreedy\":\n            self.policy = Epsilon_greedy(self.model_network,\n                                         len(actions),\n                                         self.epsilon,\n                                         self.decay_rate,\n                                         self.epoch_length)\n        \n    def act(self,states):\n        actions = self.policy.get_actions(states)\n        return actions\n    \n    def learn(self, states, actions,next_states, rewards, done):\n        if self.exp_rep:\n            self.memory.observe(states, actions, rewards, done)\n        else:\n            self.states = states\n            self.actions = actions\n            self.next_states = next_states\n            self.rewards = rewards\n            self.done = done\n\n\n    def update_model(self):\n        if self.exp_rep:\n            (states, actions, rewards, next_states, done) = self.memory.sample_minibatch(self.minibatch_size)\n        else:\n            states = self.states\n            rewards = self.rewards\n            next_states = self.next_states\n            actions = self.actions\n            done = self.done\n            \n        next_actions = []\n        Q_prime = self.model_network.predict(next_states,self.minibatch_size)\n\n        for row in range(Q_prime.shape[0]):\n            best_next_actions = np.argwhere(Q_prime[row] == np.amax(Q_prime[row]))\n            next_actions.append(best_next_actions[np.random.choice(len(best_next_actions))].item())\n        sx = np.arange(len(next_actions))\n\n        Q = self.target_model_network.predict(states,self.minibatch_size)\n\n        targets = rewards.reshape(Q[sx,actions].shape) + \\\n                  self.gamma * Q_prime[sx,next_actions] * \\\n                  (1-done.reshape(Q[sx,actions].shape))   \n        Q[sx,actions] = targets  \n        \n        loss = self.model_network.model.train_on_batch(states,Q)\n        \n        self.ddqn_update -= 1\n        if self.ddqn_update == 0:\n            self.ddqn_update = self.ddqn_time\n            self.target_model_network.model.set_weights(self.model_network.model.get_weights()) \n        \n        return loss    \n    \n        \nclass ReplayMemory(object):\n    def __init__(self, observation_size, max_size):\n        self.observation_size = observation_size\n        self.num_observed = 0\n        self.max_size = max_size\n        self.samples = {\n                 'obs'      : np.zeros(self.max_size * 1 * self.observation_size,\n                                       dtype=np.float32).reshape(self.max_size, self.observation_size),\n                 'action'   : np.zeros(self.max_size * 1, dtype=np.int16).reshape(self.max_size, 1),\n                 'reward'   : np.zeros(self.max_size * 1).reshape(self.max_size, 1),\n                 'terminal' : np.zeros(self.max_size * 1, dtype=np.int16).reshape(self.max_size, 1),\n               }\n\n    def observe(self, state, action, reward, done):\n        index = self.num_observed % self.max_size\n        self.samples['obs'][index, :] = state\n        self.samples['action'][index, :] = action\n        self.samples['reward'][index, :] = reward\n        self.samples['terminal'][index, :] = done\n\n        self.num_observed += 1\n\n    def sample_minibatch(self, minibatch_size):\n        max_index = min(self.num_observed, self.max_size) - 1\n        sampled_indices = np.random.randint(max_index, size=minibatch_size)\n\n        s      = np.asarray(self.samples['obs'][sampled_indices, :], dtype=np.float32)\n        s_next = np.asarray(self.samples['obs'][sampled_indices+1, :], dtype=np.float32)\n\n        a      = self.samples['action'][sampled_indices].reshape(minibatch_size)\n        r      = self.samples['reward'][sampled_indices].reshape((minibatch_size, 1))\n        done   = self.samples['terminal'][sampled_indices].reshape((minibatch_size, 1))\n\n        return (s, a, r, s_next, done)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:48.002081Z","iopub.execute_input":"2023-11-28T16:55:48.002785Z","iopub.status.idle":"2023-11-28T16:55:48.045922Z","shell.execute_reply.started":"2023-11-28T16:55:48.002746Z","shell.execute_reply":"2023-11-28T16:55:48.044615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nif os.path.isdir(\"models\"):\n    shutil.rmtree(\"models\", ignore_errors=False, onerror=None)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:48.047959Z","iopub.execute_input":"2023-11-28T16:55:48.048618Z","iopub.status.idle":"2023-11-28T16:55:48.061309Z","shell.execute_reply.started":"2023-11-28T16:55:48.048585Z","shell.execute_reply":"2023-11-28T16:55:48.060019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_col = 'Label'","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:48.089644Z","iopub.execute_input":"2023-11-28T16:55:48.09008Z","iopub.status.idle":"2023-11-28T16:55:48.096511Z","shell.execute_reply.started":"2023-11-28T16:55:48.090038Z","shell.execute_reply":"2023-11-28T16:55:48.094856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"models\"\n\nepsilon = 1  \n\nbatch_size = 1\n\nminibatch_size = 100\nexp_rep = True\n\niterations_episode = 100\n\ndecay_rate = 0.99\ngamma = 0.001\n\nlearning_rate = 0.001\n\nhidden_dense_layer_dict = {\"Dense_2\": {\"Size\": 64},\n                           \"Dense_3\": {\"Size\": 32}\n                           }\n\nenv = NetworkClassificationEnv('train',\n                                label_dict,\n                                batch_size = batch_size,\n                                iterations_episode = iterations_episode)\n\n# num_episodes = int(env.data_shape[0]/(iterations_episode)/10)\nnum_episodes = 300\nvalid_actions = list(range(len(env.attack_types)))\nnum_actions = len(valid_actions)\n\nobs_size = env.observation_len\n\nagent = Agent(valid_actions,\n              obs_size,\n              \"EpsilonGreedy\",\n              learning_rate = learning_rate,\n              epoch_length = iterations_episode,\n              epsilon = epsilon,\n              decay_rate = decay_rate,\n              gamma = gamma,\n              hidden_dense_layer_dict = hidden_dense_layer_dict,\n              minibatch_size=minibatch_size,\n              mem_size = 10000,\n              exp_rep=exp_rep)    \n\n\n# Statistics\nreward_chain = []\nloss_chain = []\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:55:48.443115Z","iopub.execute_input":"2023-11-28T16:55:48.444668Z","iopub.status.idle":"2023-11-28T16:56:18.351966Z","shell.execute_reply.started":"2023-11-28T16:55:48.444606Z","shell.execute_reply":"2023-11-28T16:56:18.350368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main loop\nfor epoch in range(num_episodes):\n    start_time = time.time()\n    loss = 0.\n    total_reward_by_episode = 0\n\n    states = env.reset()\n\n    done = False\n\n    true_labels = np.zeros(len(env.attack_types))\n    estimated_labels = np.zeros(len(env.attack_types))\n\n    for i_iteration in range(iterations_episode):\n        actions = agent.act(states)\n\n        estimated_labels[actions] += 1\n        true_labels[env.labels] += 1\n\n        next_states, reward, done = env.step(actions)\n        agent.learn(states, actions, next_states, reward, done)\n\n        if exp_rep and epoch*iterations_episode + i_iteration >= minibatch_size:\n            loss += agent.update_model()\n        elif not exp_rep:\n            loss += agent.update_model()\n\n        update_end_time = time.time()\n\n        states = next_states\n\n        total_reward_by_episode += np.sum(reward, dtype=np.int32)\n\n    reward_chain.append(total_reward_by_episode)    \n    loss_chain.append(loss) \n\n\n    end_time = time.time()\n    print(\"\\r|Epoch {:03d}/{:03d} | Loss {:4.4f} |\" \n            \"Tot reward in ep {:03d}| time: {:2.2f}|\"\n            .format(epoch, num_episodes \n            ,loss, total_reward_by_episode,(end_time-start_time)))\n    print(\"\\r|Estimated: {}|Labels: {}\".format(estimated_labels,true_labels))\n\nif not os.path.exists('models'):\n    os.makedirs('models')\n    \nagent.model_network.model.save_weights(\"models/DDQN_model.h5\", overwrite=True)\nwith open(\"models/DDQN_model.json\", \"w\") as outfile:\n    json.dump(agent.model_network.model.to_json(), outfile)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:56:18.354295Z","iopub.execute_input":"2023-11-28T16:56:18.354754Z","iopub.status.idle":"2023-11-28T17:00:27.087916Z","shell.execute_reply.started":"2023-11-28T16:56:18.354717Z","shell.execute_reply":"2023-11-28T17:00:27.085841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(1)\nplt.subplot(211)\nplt.plot(np.arange(len(reward_chain)),reward_chain)\nplt.title('Total reward by episode')\nplt.xlabel('n Episode')\nplt.ylabel('Total reward')\n\nplt.subplot(212)\nplt.plot(np.arange(len(loss_chain)),loss_chain)\nplt.title('Loss by episode')\nplt.xlabel('n Episode')\nplt.ylabel('loss')\nplt.tight_layout()\n#plt.show()\n\n\nif not os.path.exists('results'):\n    os.makedirs('results')\n    \nplt.savefig('results/train_type_improved.eps', format='eps', dpi=1000)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T17:00:27.089934Z","iopub.status.idle":"2023-11-28T17:00:27.090665Z","shell.execute_reply.started":"2023-11-28T17:00:27.090305Z","shell.execute_reply":"2023-11-28T17:00:27.090339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport numpy as np\nimport pandas as pd\nfrom keras.models import model_from_json\nimport matplotlib.pyplot as plt\n\nimport itertools\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import  confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:02:32.159081Z","iopub.execute_input":"2023-11-28T14:02:32.160691Z","iopub.status.idle":"2023-11-28T14:02:32.29158Z","shell.execute_reply.started":"2023-11-28T14:02:32.160631Z","shell.execute_reply":"2023-11-28T14:02:32.290112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:02:33.892087Z","iopub.execute_input":"2023-11-28T14:02:33.892684Z","iopub.status.idle":"2023-11-28T14:02:33.906012Z","shell.execute_reply.started":"2023-11-28T14:02:33.892638Z","shell.execute_reply":"2023-11-28T14:02:33.904944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"models/DDQN_model.json\", \"r\") as jfile:\n    model = model_from_json(json.load(jfile))\nmodel.load_weights(\"models/DDQN_model.h5\")\n\n\nmodel.compile(loss=huber_loss, optimizer=\"sgd\")\n\nenv = NetworkClassificationEnv('test', label_dict) ","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:02:37.422774Z","iopub.execute_input":"2023-11-28T14:02:37.423752Z","iopub.status.idle":"2023-11-28T14:02:47.379183Z","shell.execute_reply.started":"2023-11-28T14:02:37.423694Z","shell.execute_reply":"2023-11-28T14:02:47.377587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" total_reward = 0\n    \ntrue_labels = np.zeros(len(env.attack_types),dtype=int)\nestimated_labels = np.zeros(len(env.attack_types),dtype=int)\nestimated_correct_labels = np.zeros(len(env.attack_types),dtype=int)\n\nstates, labels = env.get_full()\nq = model.predict(states)\nactions = np.argmax(q, axis=1)        \n\n\nlabs, true_labels = np.unique(labels, return_counts=True)\n\nfor indx,a in enumerate(actions):\n    estimated_labels[a] +=1              \n    if a == labels[indx]:\n        total_reward += 1\n        estimated_correct_labels[a] += 1\n\n\nAccuracy = estimated_correct_labels / true_labels\nMismatch = estimated_labels - true_labels\n\nprint('\\r\\nTotal reward: {} | Number of samples: {} | Accuracy = {}%'.format(total_reward,\n      len(states),float(100*total_reward/len(states))))\noutputs_df = pd.DataFrame(index = env.attack_types,columns = [\"Estimated\",\"Correct\",\"Total\",\"Acuracy\"])\nfor indx,att in enumerate(env.attack_types):\n    outputs_df.iloc[indx].Estimated = estimated_labels[indx]\n    outputs_df.iloc[indx].Correct = estimated_correct_labels[indx]\n    outputs_df.iloc[indx].Total = true_labels[indx]\n    outputs_df.iloc[indx].Acuracy = Accuracy[indx]*100\n    outputs_df.iloc[indx].Mismatch = abs(Mismatch[indx])","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:02:47.382624Z","iopub.execute_input":"2023-11-28T14:02:47.383534Z","iopub.status.idle":"2023-11-28T14:04:19.474724Z","shell.execute_reply.started":"2023-11-28T14:02:47.383478Z","shell.execute_reply":"2023-11-28T14:04:19.473562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs_df","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:04:19.476285Z","iopub.execute_input":"2023-11-28T14:04:19.477484Z","iopub.status.idle":"2023-11-28T14:04:19.499547Z","shell.execute_reply.started":"2023-11-28T14:04:19.477418Z","shell.execute_reply":"2023-11-28T14:04:19.497863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\nwidth = 0.35\npos = np.arange(len(true_labels))\np1 = plt.bar(pos, estimated_correct_labels,width,color='g')\np1 = plt.bar(pos+width,\n             (np.abs(estimated_correct_labels-true_labels)),width,\n             color='r')\np2 = plt.bar(pos+width,np.abs(estimated_labels-estimated_correct_labels),width,\n             bottom=(np.abs(estimated_correct_labels-true_labels)),\n             color='b')\n\n\nax.set_xticks(pos+width/2)\nax.set_xticklabels(env.attack_types,rotation='vertical')\n\nax.set_title('Test set scores, Acc = {:.2f}'.format(100*total_reward/len(states)))\nplt.legend(('Correct estimated','False negative','False positive'))\nplt.tight_layout()\nplt.show()\nplt.savefig('results/ADFA_DDQN.svg', format='svg', dpi=1000)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:04:50.949486Z","iopub.execute_input":"2023-11-28T14:04:50.950266Z","iopub.status.idle":"2023-11-28T14:04:51.413369Z","shell.execute_reply.started":"2023-11-28T14:04:50.950205Z","shell.execute_reply":"2023-11-28T14:04:51.412151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggregated_data_test =labels\n\nprint('Performance measures on Test data')\nprint('Accuracy =  {:.4f}'.format(accuracy_score( aggregated_data_test,actions)))\nprint('F1 =  {:.4f}'.format(f1_score(aggregated_data_test,actions, average='weighted')))\nprint('Precision_score =  {:.4f}'.format(precision_score(aggregated_data_test,actions, average='weighted')))\nprint('recall_score =  {:.4f}'.format(recall_score(aggregated_data_test,actions, average='weighted')))\n\ncnf_matrix = confusion_matrix(aggregated_data_test,actions)\nnp.set_printoptions(precision=2)\nplt.figure()\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=env.attack_types, normalize=True,\n                      title='Normalized confusion matrix')\nplt.savefig('results/confusion_matrix_DDQN_model.svg', format='svg', dpi=1000)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T14:04:51.890383Z","iopub.execute_input":"2023-11-28T14:04:51.891211Z","iopub.status.idle":"2023-11-28T14:04:57.35102Z","shell.execute_reply.started":"2023-11-28T14:04:51.89117Z","shell.execute_reply":"2023-11-28T14:04:57.349664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}